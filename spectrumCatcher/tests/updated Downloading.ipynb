{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import os, sys\n",
    "import hashlib\n",
    "import numpy as np \n",
    "import imageio\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from txtProgressBar import printProgressBar2 as print2_\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "#gimbalDownloader\n",
    "\n",
    "class Downloader(object):\n",
    "    def __init__(self, username, password, date, directory = None):\n",
    "        super(Downloader, self).__init__()\n",
    "        self.username    = username\n",
    "        self.password    = password\n",
    "        self.date_str    = date\n",
    "        self.directory   = directory if directory != None else date\n",
    "        # self.directoryBMP= self.directory + '/raw_BMPs'\n",
    "        self.pass_hex    = None\n",
    "        self.url         = None\n",
    "        self.numShots    = 0\n",
    "        self.ID_Shots    = []\n",
    "        self.dict_whichfiles2download = {}\n",
    "        self.setWhichFiles({})\n",
    "        # self.parsed_html = None\n",
    "    def setWhichFiles(self, tmpdict):\n",
    "        self.dict_whichfiles2download['origRGB']    = tmpdict['origRGB'] if (\"origRGB\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['json']       = tmpdict['json']    if (\"json\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['rawBMPs']    = tmpdict['rawBMPs'] if (\"rawBMPs\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['CSVfull']    = tmpdict['CSVfull'] if (\"CSVfull\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['CSVcrop']    = tmpdict['CSVcrop'] if (\"CSVcrop\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['CSVspec']    = tmpdict['CSVspec'] if (\"CSVspec\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['RGBwithPOV'] = tmpdict['RGBwithPOV'] if (\"RGBwithPOV\" in tmpdict) else False\n",
    "        self.dict_whichfiles2download['BMPwithPOV'] = tmpdict['BMPwithPOV'] if (\"BMPwithPOV\" in tmpdict) else False\n",
    "        self.numWhich2down = sum(list(self.dict_whichfiles2download.values())) + (15 if self.dict_whichfiles2download['rawBMPs'] else 0)\n",
    "    def checkDir(self):\n",
    "        return os.path.isdir(self.directory)\n",
    "    def mkdir(self):\n",
    "        if self.checkDir():\n",
    "            return True\n",
    "        else:\n",
    "            try:\n",
    "                os.mkdir(self.directory)\n",
    "                # os.mkdir(self.directoryBMP)\n",
    "                return True\n",
    "            except:\n",
    "                return False\n",
    "    \n",
    "    def passConvert(self):\n",
    "        hash_obj = hashlib.md5(self.password.encode())\n",
    "        self.pass_hex = hash_obj.hexdigest()\n",
    "    \n",
    "    def mkUrl(self):\n",
    "        self.passConvert()\n",
    "        self.url = 'http://spectrumcatcher.polarstarspace.com/veggie/report/report.php?id=' + self.username + \"&v=103&c=\" + self.pass_hex + \"&data_day=\" + self.date_str\n",
    "        # print(url)\n",
    "\n",
    "    def downloadUrl(self):\n",
    "        self.mkUrl()\n",
    "        try:\n",
    "            urllib.request.urlretrieve(self.url, 'tmp1.html')\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    def processHTML(self):\n",
    "        self.mkdir()\n",
    "        self.downloadUrl()\n",
    "        html = open('tmp1.html', 'r',  encoding='utf-8').read()\n",
    "        parsed_html = BeautifulSoup(html, \"lxml\") #added\n",
    "\n",
    "        x = parsed_html.body.find('table', attrs={'class':'table table-hover'})\n",
    "        imgTimes = []\n",
    "        try:\n",
    "            for i in range(len(x)-1):\n",
    "                tmp = str(x.contents[i+1])\n",
    "                tmp1 = tmp.split(\"\\\"\")[1].split('_')\n",
    "                tmp2 = tmp1[-3] + '_'+ tmp1[-2]\n",
    "                imgTimes.append(tmp2)\n",
    "                #print(i, '\\t',  tmp2)\n",
    "            self.numShots = len(imgTimes)\n",
    "            self.ID_Shots = imgTimes\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "            #probably because of download error or no shots in that day\n",
    "\n",
    "    def download_1shot(self, each_image_id, i):\n",
    "        html = open('tmp.tmp', 'r' ,  encoding='utf-8').read()\n",
    "        parsed_html = BeautifulSoup(html, \"lxml\") #added\n",
    "        tmp = parsed_html.body.main.find('div', attrs={'class':'info-title'}).text\n",
    "        tag = tmp.split(']')[-2].split('[')[1]\n",
    "        tag = each_image_id.split('_')[1][:2] + 'h_' + tag  # this is also the folder\n",
    "        #info: angle, time, etc\n",
    "        x = parsed_html.body.main.div.div.find('div', attrs = {'class':'ndvi-table slider'})\n",
    "        x.find('div', attrs = {'class':'ndvi-text'})\n",
    "        tracks = x.find_all('div', {'class':\"ndvi-text\"})\n",
    "        infoOfShots = tracks[-2].text\n",
    "        Pitch   = infoOfShots.split('：')[3][:5]\n",
    "        Roll    = infoOfShots.split('：')[4][:5]\n",
    "        Azimuth = infoOfShots.split('：')[5][:5]\n",
    "        Exposure= infoOfShots.split('：')[7][:5]\n",
    "        #     print(Pitch, Roll, Azimuth, Exposure, end = '')\n",
    "\n",
    "\n",
    "        #folder uusgeh gej oroldoh\n",
    "        if not os.path.isdir(self.directory + \"/\" + tag):\n",
    "            os.mkdir(self.directory + \"/\" + tag)\n",
    "        \n",
    "        if not os.path.isdir(self.directory + \"/\" + tag + '/webGen'):\n",
    "            os.mkdir(self.directory + \"/\" + tag + '/webGen')\n",
    "        \n",
    "\n",
    "        tmpSubindex = 1\n",
    "        if self.dict_whichfiles2download['origRGB']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"file\", \"orig\", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_origRGB(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "        if self.dict_whichfiles2download['json']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"file\", \"json\", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_json(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "            \n",
    "            \n",
    "        if self.dict_whichfiles2download['rawBMPs']:\n",
    "            if os.path.isdir(self.directory + \"/\" + tag + '/rawBMPs'):\n",
    "                pass\n",
    "            else:\n",
    "                os.mkdir(self.directory + \"/\" + tag + '/rawBMPs')\n",
    "            for iii in range(16):\n",
    "                print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"file\", \"bmp{}\".format(iii), \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "                self.download_rawBMPs(tag, each_image_id, iii)\n",
    "                tmpSubindex += 1\n",
    "            \n",
    "        if self.dict_whichfiles2download['CSVfull']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"csv \", \"full\", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_CSVfull(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "        \n",
    "        if self.dict_whichfiles2download['CSVcrop']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"csv \", \"crop\", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_CSVcrop(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "        \n",
    "        \n",
    "        if self.dict_whichfiles2download['CSVspec']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"csv \", \"spec\", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_CSVspec(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "            \n",
    "        if self.dict_whichfiles2download['RGBwithPOV']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"rgb \", \"pov \", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_RGBwithPOV(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "            \n",
    "        if self.dict_whichfiles2download['BMPwithPOV']:\n",
    "            print2_(tmpSubindex, self.numWhich2down, i+1, self.numShots, \"bmp \", \"pov \", \"\\tSet\", \"Complete\", length=self.numWhich2down, length1=20)\n",
    "            self.download_BMPwithPOV(tag, each_image_id)\n",
    "            tmpSubindex += 1\n",
    "\n",
    "\n",
    "    def download_origRGB(self, tag, each_image_id):\n",
    "        urlname = \"http://spectrumcatcher.polarstarspace.com/veggie/results/\"+self.username+\"/VeggieCamera_crops_picture_\" + each_image_id + \".jpg\"\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/' + each_image_id + \".jpg\")\n",
    "        \n",
    "    def download_json(self, tag, each_image_id):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/results/'+self.username+'/VeggieCamera_crops_device_' + each_image_id + \".json\"\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/' + each_image_id + \".json\")\n",
    "    \n",
    "    def download_rawBMPs(self, tag, each_image_id, iii):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/results/'+self.username+'/VeggieCamera_crops_spectrum_'+each_image_id+'_'+str(iii)+'.bmp'\n",
    "        try:\n",
    "            fName = self.directory + \"/\" + tag  + '/rawBMPs/' + each_image_id + \"_\"+str(iii)+\".bmp\"\n",
    "            urllib.request.urlretrieve(urlname,  fName)\n",
    "            im = Image.open(fName)\n",
    "            tmpy = np.array(im)\n",
    "            im = Image.fromarray(tmpy.transpose()).transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            im = Image.fromarray(tmpy.transpose().transpose(Image.FLIP_LEFT_RIGHT))\n",
    "            im.save(fName)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "    def download_CSVfull(self, tag, each_image_id):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/results/'+self.username+'/' + each_image_id + \"_full.csv\"\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/webGen/' + each_image_id + \"_full.csv\")\n",
    "        \n",
    "    def download_CSVcrop(self, tag, each_image_id):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/results/'+self.username+'/' + each_image_id + \"_crop.csv\"\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/webGen/' + each_image_id + \"_crop.csv\")\n",
    "        \n",
    "    def download_CSVspec(self, tag, each_image_id):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/results/'+self.username+'/' + each_image_id + \"_spec_NDVI.csv\"\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/webGen/' + each_image_id + \"_spec_NDVI.csv\")\n",
    "    \n",
    "    def download_RGBwithPOV(self, tag, each_image_id):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/report/view_photo.php?id='+self.username+'&pic_id=' + each_image_id\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/webGen/' + each_image_id + \".jpeg\")\n",
    "        \n",
    "        \n",
    "    def download_BMPwithPOV(self, tag, each_image_id):\n",
    "        urlname = 'http://spectrumcatcher.polarstarspace.com/veggie/results/'+self.username+'/' + each_image_id + \"_rotate.png\"\n",
    "        urllib.request.urlretrieve(urlname,  self.directory + \"/\" + tag  + '/webGen/' + each_image_id + \".png\")\n",
    "\n",
    "    def download_1shot_i(self, i):\n",
    "        self.download_1shot(self.ID_Shots[i], i)\n",
    "\n",
    "    def download_set(self):\n",
    "        for i in range(self.numShots):\n",
    "            self.download_1shot(self.ID_Shots[i], i)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class Copier(object):\n",
    "    def __init__(self, ip):#, date = None, directory = None):\n",
    "        self.ip          = ip\n",
    "        #         self.date_str    = date\n",
    "        #         self.directory   = directory if directory != None else date\n",
    "        self.numShots    = 0\n",
    "        self.ID_Shots    = []\n",
    "        self.dict_whichfiles2download = {}\n",
    "        #         self.setWhichFiles({})\n",
    "        self.parser = self.MyHTMLParser()\n",
    "        self.allRawFnames = []\n",
    "        self.allPosibleDates = []\n",
    "        self.allRawFnamesDict = None\n",
    "   \n",
    "        \n",
    "    def downloadHTML(self):\n",
    "        url = 'http://{}:8080/storage/emulated/0/Android/data/com.polarstarspace.veggiecamera/files'.format(self.ip)\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        tmpfile = open('inPhone.html', 'wb')\n",
    "        tmpfile.write(r.content)\n",
    "        tmpfile.close()\n",
    "        \n",
    "    def processHTML(self, display = None):\n",
    "        tmpfile = open('inPhone.html', 'r')\n",
    "        html = tmpfile.read()\n",
    "        self.parser.feed(html)\n",
    "        self.allRawFnames, self.allPosibleDates, self.allRawFnamesDict = self.parser.getPhonesDate()\n",
    "        tmpfile.close()\n",
    "        print((\"All measurement dates in the phone (at {}) are:\\n=======================================================\\n{}\".format(self.ip , self.allRawFnamesDict_str()) if True else ''), end = '')\n",
    "    \n",
    "    def allRawFnamesDict_str(self):\n",
    "        tmp = ''\n",
    "        for a1date in list(c.allRawFnamesDict.keys()):\n",
    "            fnamesIna1date = c.allRawFnamesDict[a1date]\n",
    "            numFiles = len(fnamesIna1date)\n",
    "            numJsons = len([fname for fname in fnamesIna1date if \"json\" in fname])\n",
    "            numJpgs  = len([fname for fname in fnamesIna1date if \"jpg\" in fname])\n",
    "            numBMPs  = len([fname for fname in fnamesIna1date if \"bmp\" in fname])\n",
    "            tmp_ = \"date {}:\\t{}files={}jsos +{}jpgs +{}bmps\".format(a1date, str(numFiles).rjust(7, ' '), str(numJsons).rjust(5, ' '),str(numJpgs).rjust(5, ' ') , str(numBMPs).rjust(6, ' '))\n",
    "            tmp += tmp_\n",
    "        return tmp\n",
    "    \n",
    "    def download1day(self, date, directory = None):\n",
    "        if not (date in c.allRawFnamesDict.keys()):\n",
    "            print(\"Error there no files related to day:{}\".format(date))\n",
    "            print(\"Posssible dates are: {}\".format(list(c.allRawFnamesDict.keys())))\n",
    "        fnames1date = c.allRawFnamesDict[date]\n",
    "        numFiles = len(fnames1date)\n",
    "        numJsons = len([fname for fname in fnames1date if \"json\" in fname])\n",
    "        numJpgs  = len([fname for fname in fnames1date if \"jpg\" in fname])\n",
    "        numBMPs  = len([fname for fname in fnames1date if \"bmp\" in fname])\n",
    "        self.tmpdir = directory if directory != None else date\n",
    "        if not os.path.isdir(self.tmpdir):\n",
    "            os.mkdir(self.tmpdir)\n",
    "        self.rawBMPsDir = os.path.join(self.tmpdir, \"rawBMPs\")\n",
    "        if not os.path.isdir(self.rawBMPsDir):\n",
    "            os.mkdir(self.rawBMPsDir)\n",
    "        countF = 1\n",
    "        countJ = 1\n",
    "        countR = 1\n",
    "        countB = 1\n",
    "        for fname in fnames1date:\n",
    "            if   \".json\" in fname:\n",
    "                os.system('wget http://{}:8080/storage/emulated/0/Android/data/com.polarstarspace.veggiecamera/files/VeggieCamera_crops_device_{} -O {}'.format(self.ip, fname, os.path.join(self.tmpdir, fname)))\n",
    "                os.system(\"echo \\\"\" +  fname + \"\\\" >> \" + os.path.join(self.tmpdir, \"id.txt\"))\n",
    "                print2_(countJ, numJsons, countF, numFiles, \"{} json: \".format(date), fname, \"\\tWhole Set\", \"Complete\\t\", length=15, length1=15)\n",
    "                countJ +=1\n",
    "            elif \".jpg\" in fname:\n",
    "                os.system('wget http://{}:8080/storage/emulated/0/Android/data/com.polarstarspace.veggiecamera/files/VeggieCamera_crops_picture_{} -O {}'.format(self.ip, fname, os.path.join(self.tmpdir, fname) ))\n",
    "                print2_(countR, numJpgs, countF, numFiles, \"{} jpg: \".format(date), fname, \"\\tWhole  Set\", \"Complete\\t\", length=15, length1=15)\n",
    "                countR +=1\n",
    "            elif \".bmp\" in fname:\n",
    "                os.system('wget http://{}:8080/storage/emulated/0/Android/data/com.polarstarspace.veggiecamera/files/VeggieCamera_crops_spectrum_{} -O {}'.format(self.ip, fname, os.path.join(self.rawBMPsDir, fname)))\n",
    "                print2_(countB, numBMPs, countF, numFiles, \"{}  bmp: \".format(date), fname, \"\\tWhole Set\", \"Complete\\t\", length=15, length1=15)\n",
    "                countB +=1\n",
    "            countF+=1\n",
    "    class MyHTMLParser(HTMLParser):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.allPosibleDates = []\n",
    "            self.allRawFnames = []\n",
    "            self.lastdate = ''\n",
    "            self.allRawFnamesDict = {}\n",
    "            \n",
    "        def handle_starttag(self, tag, attrs):\n",
    "            pass\n",
    "            #print(\"Encountered a start tag:\", tag)\n",
    "\n",
    "        def handle_endtag(self, tag):\n",
    "            pass\n",
    "            #print(\"Encountered an end tag :\", tag)\n",
    "\n",
    "        def handle_data(self, data):\n",
    "            #print(data)\n",
    "            if ('.json' in data) or ('jpg' in data) or ('bmp' in data):\n",
    "                self.allRawFnames.append(data)\n",
    "                if ('.json' in data): #example VeggieCamera_crops_device_20201108_170014.json\n",
    "                    curdate = data.split('_')[3]\n",
    "                    if curdate != self.lastdate:\n",
    "                        self.allPosibleDates.append(curdate)\n",
    "                        self.lastdate = curdate\n",
    "                        self.allRawFnamesDict[curdate] = [] \n",
    "                    self.allRawFnamesDict[curdate].append('{}_{}'.format(data.split('_')[3], data.split('_')[4]))\n",
    "                if ('.jpg' in data): #example VeggieCamera_crops_picture_20201108_170033.jpg\n",
    "                    curdate = data.split('_')[3]\n",
    "                    if curdate != self.lastdate:\n",
    "                        self.allPosibleDates.append(curdate)\n",
    "                        self.lastdate = curdate\n",
    "                        self.allRawFnamesDict[curdate] =[]\n",
    "                    self.allRawFnamesDict[curdate].append('{}_{}'.format(data.split('_')[3], data.split('_')[4]))\n",
    "                \n",
    "                if ('.bmp' in data): #VeggieCamera_crops_spectrum_20201108_164859_0.bmp\n",
    "                    curdate = data.split('_')[3]\n",
    "                    if curdate != self.lastdate:\n",
    "                        self.allPosibleDates.append(curdate)\n",
    "                        self.lastdate = curdate\n",
    "                        self.allRawFnamesDict[curdate] = []\n",
    "                    self.allRawFnamesDict[curdate].append('{}_{}_{}'.format(data.split('_')[3], data.split('_')[4], data.split('_')[5]))\n",
    "                \n",
    "                    \n",
    "        def getPhonesDate(self):\n",
    "            return self.allRawFnames, self.allPosibleDates, self.allRawFnamesDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Downloader(\"mkuriki\", \"mkuriki\", \"2020-11-08\", \"dname1108\")\n",
    "Types = {\n",
    "    \"origRGB\"  : True,\n",
    "    \"json\"     : True,\n",
    "    \"rawBMPs\"  : True,\n",
    "    \"CSVfull\"  : True,\n",
    "    \"CSVcrop\"  : True,\n",
    "    \"CSVspec\"  : True,\n",
    "    \"RGBwithPOV\": True,\n",
    "    \"BMPwithPOV\": True,\n",
    "}\n",
    "d.setWhichFiles(Types)\n",
    "d.processHTML()\n",
    "d.download_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All measurement dates in the phone (at 192.168.11.4) are:\n",
      "=======================================================\n",
      "date 20201211:\t    612files=   36jsos +   36jpgs +   540bmps"
     ]
    }
   ],
   "source": [
    "c = Copier('192.168.11.4')\n",
    "Types = {\n",
    "    \"origRGB\"  : True,\n",
    "    \"json\"     : True,\n",
    "    \"rawBMPs\"  : True}\n",
    "# c.setWhichFiles(Types)\n",
    "c.downloadHTML()\n",
    "c.processHTML(display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201211  bmp:  |███████████████| 100.0% 20201211_192221_9.bmp \tWhole Set |███████████████| 100.0% Complete\t \n"
     ]
    }
   ],
   "source": [
    "c.download1day('20201211')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
